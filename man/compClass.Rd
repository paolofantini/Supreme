% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/compClass.R
\name{compClass}
\alias{compClass}
\title{Internal Supreme function}
\usage{
compClass(predictors, classes, inTraining, train.glmnet = FALSE,
  cv.parallel = FALSE, train.parallel = FALSE)
}
\arguments{
\item{predictors}{the matrix of predictors, i. e. the posterior topic compositions of each document.}

\item{classes}{factor, the classification variable.}

\item{inTraining}{the numeric ids of documents belonging to the training set.}

\item{train.glmnet}{logical. If \code{TRUE} run \code{train.glmnet} function from package \pkg{caret}. Default is \code{FALSE}.}

\item{cv.parallel}{logical. If \code{TRUE} parallel computation is used in \emph{Method1} with the maximum number of available cores. Default is \code{FALSE}.}

\item{train.parallel}{logical. If \code{TRUE} parallel computation is used in \emph{Method2} with the maximum number of available cores. Default is \code{FALSE}.}
}
\value{
\code{err} list of misclassification errors (error = 1 - Accuracy) and confusion matrices (from package \pkg{caret}):
\item{e0.train}{train error from method "glmnet"}
\item{e1.train}{train error from method "cv.glmnet"}
\item{e2.train}{train error from method "train.glmnet"}
\item{e0.test}{test error from method "predict.glmnet"}
\item{e1.test}{test error from method "predict.cv.glmnet"}
\item{e2.test}{test error from method "predict.train.glmnet"}
\item{cm0}{confusion matrix for method "glmnet"}
\item{cm1}{confusion matrix for method "cv.glmnet"}
\item{cm1}{confusion matrix for method "train.glmnet"}
}
\description{
\code{compClass} fits a logistic classification model (from packages \pkg{glmnet} and \pkg{caret})
to the posterior topic \code{compositions} of each document as trained by Latent Dirichelet Allocation.
A \code{classes} variable is used as a classification variable.
\code{compClass} is called by the \code{\link{mcLDA}} function.
}
\details{
This function recognizes the compositional nature of the predictors
and applies the \emph{principle of working on coordinates} when facing with compositional data.
Isometric log-ratio transformed versions of the predictors
(by the \code{ilr} function from package \pkg{compositions}) are provided as input to the classification model.

We considered three different methods.

\emph{Method0} and \emph{Method1} are respectively built on the functions \code{glmnet} and \code{cv.glmnet} from package \pkg{glmnet}.
\emph{Method2} refers to the function \code{train.glmnet} from package \pkg{caret}.
\emph{Method0} tends to overfit the training set.
\emph{Method1} and \emph{Method2} try to avoid overfitting problems using cross-validation.
\emph{Method2} uses repeated cross-validation and is more stable than \emph{Method1} but much more time-consuming (parallel computation is allowed).
}
\note{
Tuning parameters are \code{alpha} and \code{lambda}.
\emph{Method0} and \emph{Method1} pick no value for \code{alpha} and it remains at default value \code{alpha = 1}.
\emph{Method2} selects values for \code{alpha} and \code{lambda} using the tuning parameter grid defined by
\code{expand.grid(alpha = seq(0.1, 1, 0.1), lambda = glmnetFit0$lambda)}.
More details can be found \href{http://caret.r-forge.r-project.org/training.html}{here}.
In \emph{Method1} the best model is selected using the "one standard error rule":
default best value of the penalty parameter \code{lambda} is \code{s = "lambda.1se"}, stored on the \code{cv.glmnet} object.
Such a rule takes a conservative approach. Alternatively \code{s = "lambda.min"} can be used.
Full details are given in \emph{"The Elements of Statistical Learnings"} (T. Hastie, R. Tibshirani, J. Friedman) 2nd edition p. 61.
Insights on compositions and their use in R can be found in \emph{"Analyzing compositional data with R"}
(K. Gerald van den Boogaart, Raimon Tolosana-Delgado) Springer-Verlag 2013.
}
\examples{
\dontrun{
library(Supreme)
library(topicmodels)

# Input data.
data("dtm")
data("classes")

# Reduced dtm.lognet
dtm.lognet <- reduce_dtm(dtm, method = "lognet", classes = classes, export = TRUE)

# Run a 35-topic model over the reduced dtm.lognet and compute the topic posteriors.
ldaVEM.mod <- LDA(dtm.lognet$reduced, k = 35, method = "VEM", control = list(seed = 2014))
topic.posteriors <- posterior(ldaVEM.mod)$topics

# Misclassification errors.
set.seed(2010)  # for inTraining reproducibility
inTraining <- caret::createDataPartition(as.factor(classes), p = 0.75, list = FALSE)  # for balancing the size of target classes in training set
mis.error <- compClass(topic.posteriors, classes, inTraining)
}
}

